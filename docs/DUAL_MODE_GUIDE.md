# Dual-Mode Voice Assistant Guide

## Overview

Your Misty voice assistant now supports **two different processing modes** that you can switch between based on your needs:

### üê¢ Traditional Mode (STT ‚Üí GPT ‚Üí TTS)
**Current default mode** - Slower but more stable

**How it works:**
1. Speech captured ‚Üí Whisper transcribes to text (~1-2s)
2. Text sent to GPT for response (~2-3s)
3. Response converted to speech via Misty TTS (~2-3s)
4. **Total: ~5-8 seconds**

**Pros:**
- ‚úÖ More stable and mature technology
- ‚úÖ Works with all GPT models (gpt-4, gpt-4o, gpt-4o-mini)
- ‚úÖ Easier to debug (you see the text at each step in logs)
- ‚úÖ Better for complex conversations with context
- ‚úÖ Conversation history maintained

**Cons:**
- ‚ùå Higher latency (~5-8 seconds feels slow)
- ‚ùå More API calls (costs slightly more)

---

### ‚ö° Realtime Mode (Voice ‚Üí Voice)
**New faster mode** - Much quicker responses

**How it works:**
1. Speech captured ‚Üí Sent directly to OpenAI Realtime API
2. AI processes voice and responds with voice (~1-3s total)
3. **Total: ~1-3 seconds**

**Pros:**
- ‚úÖ Much faster (~1-3 seconds feels natural)
- ‚úÖ More natural conversation flow
- ‚úÖ Lower cost (single API call instead of 3)
- ‚úÖ Streaming audio responses

**Cons:**
- ‚ö†Ô∏è Only works with `gpt-4o-realtime-preview` model
- ‚ö†Ô∏è Newer technology (less mature, may have edge cases)
- ‚ö†Ô∏è Harder to debug (audio ‚Üí audio, no text visibility)

---

## How to Switch Modes

### Option 1: Edit your `.env` file

Open your `.env` file and change the `VOICE_MODE` setting:

```bash
# For traditional mode (current default)
VOICE_MODE=traditional

# For realtime mode (faster)
VOICE_MODE=realtime
```

Then restart your application:
```bash
source venv/bin/activate
python misty_aicco_assistant.py
```

### Option 2: Set environment variable

```bash
# Traditional mode
export VOICE_MODE=traditional

# Realtime mode
export VOICE_MODE=realtime
```

---

## When to Use Which Mode?

### Use **Traditional Mode** when:
- üîß You're debugging or developing
- üìö You need complex conversations with context
- üéØ You want maximum stability
- üìù You need to see what was said (text logs)
- üí∞ You're using a cheaper model (gpt-4o-mini)

### Use **Realtime Mode** when:
- ‚ö° You want the fastest responses possible
- üí¨ You're doing simple Q&A conversations
- üé≠ You want the most natural conversation feel
- üé§ Audio quality is more important than debugging
- üíµ You're okay with using gpt-4o-realtime-preview

---

## Testing the Configuration

Run the test script to verify both modes work:

```bash
source venv/bin/activate
python test_dual_mode.py
```

You should see:
```
‚úÖ ALL TESTS PASSED!
```

---

## Configuration Example

Here's what your `.env` should look like:

```bash
# Misty Configuration
MISTY_IP_ADDRESS=10.66.239.83
OPENAI_API_KEY=sk-your-key-here

# Voice Mode Selection
VOICE_MODE=realtime           # Switch to "traditional" for slower but stable mode

# Wake Word Settings
WAKE_WORD_MODE=misty_builtin  # Uses "Hey Misty"

# Other settings...
FACE_RECOGNITION_ENABLED=true
VOICE_ASSISTANT_ENABLED=true
```

---

## What You'll See

### Traditional Mode Startup:
```
Setting up TRADITIONAL mode (STT ‚Üí GPT ‚Üí TTS)...
  - Setting up OpenAI Whisper for speech-to-text...
    ‚úÖ STT initialized (model: whisper-1)
  - Setting up OpenAI Chat for AI responses...
    ‚úÖ Chat initialized (model: gpt-4o-mini)
  ‚ö†Ô∏è  Expected latency: ~5-8 seconds per response
```

### Realtime Mode Startup:
```
Setting up REALTIME mode (voice ‚Üí voice)...
  - Connecting to OpenAI Realtime API...
    ‚úÖ Realtime API connected
  ‚ö° Expected latency: ~1-3 seconds per response
```

---

## Troubleshooting

### "Realtime mode is not available"
- Make sure you have a valid OpenAI API key
- Check your internet connection
- The Realtime API may be experiencing issues

### "Configuration Error"
- Run `python test_dual_mode.py` to verify your config
- Make sure `VOICE_MODE` is set to either `traditional` or `realtime`
- Check that your `.env` file exists and is properly formatted

### Slow responses in Realtime mode
- Realtime mode should be 1-3 seconds
- If it's slower, check your internet speed
- Try switching back to traditional mode temporarily

---

## Summary

**Current Setup:** You have both modes available and can switch anytime!

**Quick Switch:**
```bash
# Edit .env file
nano .env

# Change this line:
VOICE_MODE=realtime    # or "traditional"

# Restart
python misty_aicco_assistant.py
```

**My Recommendation:** Try realtime mode! It's much faster and feels more natural for conversations. If you encounter any issues, you can always switch back to traditional mode.

---

## Files Created

- `config.py` - Updated with `voice_mode` configuration
- `realtime_handler.py` - New handler for OpenAI Realtime API
- `misty_aicco_assistant.py` - Updated to support both modes
- `env.example` - Updated with new configuration options
- `test_dual_mode.py` - Test script to verify both modes
- `DUAL_MODE_GUIDE.md` - This guide!

